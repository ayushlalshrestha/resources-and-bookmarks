Kinesis: 
- Real time streaming of Big data.
- allows you to ingest, process, and analyze real-time streaming data.
- think of it as a huge data highway.

Kinesis data streams
- capture, process & store data streams
- Stream partitioned to different shards (as partitions in different brokers in kafka).
- A partition key is hashed to point to a shard which stores the message.
- Partition key in a message from the producer determines which shard the log will be saved to.
- A record consists of Partition key, sequence number & data blob upto 1MB.
- Retention: 1 day to 1 year.
- Maximum of 1000 writes per second in a single shard.
- Producers: Kinesis Agent, AWS SDK for Java, KPL (kinesis producer library)
- Consumers: Kinesis data analytics, KCL (kinesis consumer library)


Kinesis Data Firehose
- Load data streams into AWS data store (eg. S3)
- Acts as a store_handler
- Data transfer tool to get information to S3, redshift, elasticsearch.


Kinesis Data Analytics
- Run standard SQL queries against data streams.
- Take data from sources like data stream, firehose.
- Analyze data streams with SQL or Apache Flink.

Amazon Athena
- interactive query service to analyze data in S3 using SQL
- directly query data in S3
- use Glue for ETL (discover, prepare, combine)
    - Glue crawlers get the unstructured data
    - Then to Glue data catalog
    - which can then be queried by Athena or sent to redshift spectrum

Notes:
- Amazon MQ as alternative to RabbitMQ